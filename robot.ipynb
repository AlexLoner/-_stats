{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from user_agent import generate_user_agent\n",
    "import selenium\n",
    "from selenium.webdriver import Firefox, Chrome, Remote\n",
    "from selenium.webdriver.common.proxy import *\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.support.ui import WebDriverWait\n",
    "# from selenium.webdriver.support import expected_conditions as EC\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_abstract(name, page):\n",
    "    '''\n",
    "    Пытается найти абстракт со страницы page,\n",
    "    если его нет, то вызывает get_abstract.\n",
    "    В результате выводит абстракт или \"\", если get_abstract также не нашел его на сайте издателя.\n",
    "    '''\n",
    "    abstract = page.find('p').text\n",
    "    key = 'https://doi'\n",
    "    if abstract:\n",
    "        return abstract\n",
    "    else:\n",
    "        for i in page.findAll('a'):\n",
    "            try:\n",
    "                if key in i['href']:\n",
    "                    adress_r = i['href']\n",
    "                    break\n",
    "            except:\n",
    "                continue\n",
    "        try:\n",
    "            browser.get(adress_r)\n",
    "            ppp = BeautifulSoup(browser.page_source, \"html.parser\")\n",
    "            return get_abstract(name, ppp)\n",
    "        except:\n",
    "            return ''\n",
    "        \n",
    "def get_abstract(name, page):\n",
    "    '''\n",
    "    Функция возвращает абстакт для журнала name\n",
    "    '''\n",
    "    def nature(page):\n",
    "        try: return page.findAll('p')[5].text\n",
    "        except: return ''\n",
    "    def jetp(page):\n",
    "        try: return page.findAll('p')[3].text\n",
    "        except: return \"\"\n",
    "    def physrev(page):\n",
    "        try:\n",
    "            mass_txt = p.find('p').text.split('&lt;math')\n",
    "            abstract = ''\n",
    "            for i in mass_txt: \n",
    "                abstract += i.split('math&gt;')[-1]\n",
    "            return abstract\n",
    "        except: return \"\"\n",
    "    \n",
    "    func = {\n",
    "        'NATURE_PHYSICS' : nature,\n",
    "        'JETP' : jetp,\n",
    "        'JETP_LETTERS' : jetp,\n",
    "        'PHYSICAL_REVIEW_B': physrev,\n",
    "        'PHYSICAL_REVIEW_LETTERS': physrev,\n",
    "        'PHYSICAL_REVIEW_C': physrev\n",
    "    }\n",
    "    return func[name](page)\n",
    "\n",
    "def year(page):\n",
    "    '''\n",
    "    Возвращает год публикации, если не указан, то возвращает 1000\n",
    "    '''\n",
    "    try:\n",
    "        for i in page.findAll('font',attrs={'color':['#00008f']}) :\n",
    "            if i.text[:3] == '201':\n",
    "                return i.text\n",
    "    except:\n",
    "        return '1000'\n",
    "        \n",
    "def get_articles_adress(page):\n",
    "    '''\n",
    "    Возвращает список адресов всех статей\n",
    "    '''\n",
    "    articles_adress = []\n",
    "    id_str = '/item.asp?id='\n",
    "    for i in page.findAll('a'):\n",
    "        try:\n",
    "            if id_str in i['href']:\n",
    "                num_id = i['href']\n",
    "                articles_adress.append('https://elibrary.ru' + num_id)\n",
    "        except:\n",
    "            continue\n",
    "    return articles_adress\n",
    "\n",
    "def get_authors_title(page):\n",
    "    mas = []\n",
    "    for i in page.findAll('input'):\n",
    "        try:    \n",
    "            if not i['value'][0].isdigit() and (i['value'][0] == i['value'][0].upper()):\n",
    "                mas.append(i['value'])\n",
    "        except:\n",
    "            continue\n",
    "    if len(mas) < 2:\n",
    "        mas.insert(0, 'Incognito')\n",
    "    return mas\n",
    "\n",
    "def get_quot(page, adress):\n",
    "    try:\n",
    "        return page.findAll('a', attrs= {'href':['cit_items.asp?id=' + adress.split('=')[-1]]})[0].text\n",
    "    except:\n",
    "        return '0'\n",
    "\n",
    "def find_data(browser, name, adress):\n",
    "    '''\n",
    "    Возвращает list из [названия статьи, авторы, число цитирований, абстракт]\n",
    "    '''\n",
    "    soup = BeautifulSoup(browser.page_source, \"html.parser\")\n",
    "    sleep(np.random.rand() * 2)\n",
    "    data = []\n",
    "    data.append(year(soup))\n",
    "    # Добавление Автора и Названия статьи\n",
    "    authors, title = get_authors_title(soup)\n",
    "    data.append(authors)\n",
    "    data.append(title)\n",
    "    # Добавление количества цитирований\n",
    "    data.append(get_quot(soup, adress))\n",
    "    # Добавление абстракта\n",
    "    data.append(find_abstract(name, soup))\n",
    "    sleep(1 + 3 * np.random.random())\n",
    "    browser.back()\n",
    "    return data\n",
    "\n",
    "def run_to_actual_page(page_num,browser,xp_main):\n",
    "    for i in range(page_num):\n",
    "        sleep(7)\n",
    "        search_form = browser.find_element_by_xpath(xp_main)\n",
    "        search_form.click()                                                                  # Жмякаем на кнопку\n",
    "\n",
    "def data_frame(name):\n",
    "    try:\n",
    "        return pd.read_csv(name,sep=\"@\")\n",
    "    except:\n",
    "        return pd.DataFrame(columns=['Year','Authors', 'Title', 'Qoutes', 'Abstract', 'Link'])\n",
    "    \n",
    "def parse_journal(name, browser, page_num):\n",
    "    print(name)\n",
    "    print()\n",
    "    columns = ['Year', 'Authors', 'Title', 'Qoutes', 'Abstract', 'Link']\n",
    "    articles = data_frame(name)\n",
    "    xp_main = '//*[@id=\"pages\"]/table/tbody/tr/td[13]/a'\n",
    "    run_to_actual_page(page_num, browser, xp_main)\n",
    "    pp = BeautifulSoup(browser.page_source, \"html.parser\")\n",
    "    runs = int(pp.find('font',attrs={'color':['#ff0000']}).text) // 20\n",
    "    print('runs:', runs)\n",
    "    sleep(5)\n",
    "    for loop in range(page_num, runs):\n",
    "        \n",
    "        search_form = browser.find_element_by_xpath(xp_main)\n",
    "        page = BeautifulSoup(browser.page_source, \"html.parser\")                             \n",
    "        new_id = get_articles_adress(page)                                                   \n",
    "        if loop % 2:\n",
    "            sleep(5 + 10 * np.random.random())\n",
    "        for i in np.random.choice(range(len(new_id)), 15, replace=False):\n",
    "            if i % 3 == 0:\n",
    "                sleep(3 * np.random.random() + 1.5 * np.random.random())\n",
    "            browser.get(new_id[i])                         \n",
    "            d = find_data(browser, name, new_id[i])\n",
    "            d.append(new_id[i])                                                                    \n",
    "            print(\"___{0}___{1}___\".format(loop, i), end='\\r')\n",
    "            sleep(2 + 5 * np.random.random())\n",
    "            browser.back()\n",
    "            articles = articles.append(pd.Series(d, index=columns), ignore_index=True)\n",
    "            articles.to_csv(name, sep=\"@\")\n",
    "        search_form = browser.find_element_by_xpath(xp_main)\n",
    "        search_form.click()                                                                  \n",
    "        sleep(5)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = Chrome(executable_path=\"./chromedriver\")   \n",
    "journals = {\n",
    "    'NATURE_PHYSICS'    : 'https://elibrary.ru/title_items.asp?id=25368',\n",
    "    'JETP' : 'https://elibrary.ru/title_items.asp?id=7467',\n",
    "    'JETP_LETTERS' : 'https://elibrary.ru/title_items.asp?id=7468',\n",
    "    'PHYSICAL_REVIEW_B' : \"https://elibrary.ru/title_items.asp?id=21814\",\n",
    "    'PHYSICAL_REVIEW_C' : \"https://elibrary.ru/title_items.asp?id=21815\",\n",
    "    'PHYSICAL_REVIEW_LETTERS' : \"https://elibrary.ru/title_items.asp?id=21820\",\n",
    "    \n",
    "}\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('PHYSICAL_REVIEW_B', 'https://elibrary.ru/title_items.asp?id=21814')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = list(journals.items())\n",
    "j[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHYSICAL_REVIEW_B\n",
      "\n",
      "runs: 3094\n",
      "___1___0____\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-47a07422e485>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbrowser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#r = input()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mparse_journal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbrowser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-83-b67a138e056b>\u001b[0m in \u001b[0;36mparse_journal\u001b[0;34m(name, browser, page_num)\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mbrowser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbrowser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"___{0}___{1}___\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-83-b67a138e056b>\u001b[0m in \u001b[0;36mfind_data\u001b[0;34m(browser, name, adress)\u001b[0m\n\u001b[1;32m    102\u001b[0m     '''\n\u001b[1;32m    103\u001b[0m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbrowser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"html.parser\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "browser.get(j[3][1])\n",
    "#r = input()\n",
    "parse_journal(j[3][0], browser, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = Chrome(executable_path=\"./chromedriver\")   \n",
    "browser.get('https://journals.aps.org/prc/abstract/10.1103/PhysRevC.92.064002')\n",
    "p = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "# get_abstract('JETP_LETTERS', p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
